{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7192c0e6-6e5f-4125-8bf0-3d454a3908f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "sys.path.append(str((Path.cwd().parent / \"data\").resolve()))\n",
    "\n",
    "\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "\n",
    "from data_generation import date_generation, feature_generation\n",
    "from impact_factors import (\n",
    "    add_holiday_features,\n",
    "    add_day_of_week_features,\n",
    "    add_month_over_month_growth_features,\n",
    "    add_covid_store_features,\n",
    "    add_total_impact_features,\n",
    "    add_random_noise_features,\n",
    "    add_seasonality_features,\n",
    "    remove_helper_columns,\n",
    "    explode_by_simulated_volume,\n",
    "    add_quantity_sold\n",
    ")\n",
    "from dimensions import (\n",
    "    add_dim_product_key, add_dim_customer_key,\n",
    "    create_dim_product, create_dim_customer,\n",
    "    create_dim_store, create_dim_date\n",
    ")\n",
    "\n",
    "\n",
    "root = Path(os.getcwd()).parent / \"bundle/src/transformations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd6a037-0cb6-4393-a063-c9bcaba87c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_store_dataframe(\n",
    "    base_dates_df: DataFrame,\n",
    "    store_config: Dict\n",
    ") -> DataFrame:\n",
    "    store_dates_df = base_dates_df.withColumn(\"date\", F.to_date(\"date\"))\n",
    "\n",
    "    if store_config.get(\"store_start_date\"):\n",
    "        store_dates_df = store_dates_df.filter(\n",
    "            F.col(\"date\") >= F.to_date(F.lit(store_config[\"store_start_date\"]))\n",
    "        )\n",
    "\n",
    "    if store_config.get(\"store_end_date\"):\n",
    "        store_dates_df = store_dates_df.filter(\n",
    "            F.col(\"date\") <= F.to_date(F.lit(store_config[\"store_end_date\"]))\n",
    "        )\n",
    "\n",
    "    df = feature_generation(\n",
    "        dates_df=store_dates_df,\n",
    "        store_key=store_config[\"store_key\"],\n",
    "        base_volume=store_config[\"base_volume\"],\n",
    "        covid_sales_impact_factor=store_config[\"covid_sales_impact_factor\"],\n",
    "        covid_impact_start_date=store_config[\"covid_impact_start_date\"],\n",
    "        covid_impact_end_date=store_config[\"covid_impact_end_date\"],\n",
    "    )\n",
    "\n",
    "    df = add_random_noise_features(df, stddev=store_config.get(\"noise_stddev\", 0.05), seed=store_config.get(\"noise_seed\", 1))\n",
    "    df = add_holiday_features(df)\n",
    "    df = add_day_of_week_features(\n",
    "        df,\n",
    "        mon_factor=store_config.get(\"mon_factor\", 0.95),\n",
    "        tue_factor=store_config.get(\"tue_factor\", 1.0),\n",
    "        wed_factor=store_config.get(\"wed_factor\", 1.05),\n",
    "        thu_factor=store_config.get(\"thu_factor\", 1.05),\n",
    "        fri_factor=store_config.get(\"fri_factor\", 1.1),\n",
    "        sat_factor=store_config.get(\"sat_factor\", 1.2),\n",
    "        sun_factor=store_config.get(\"sun_factor\", 1.1),\n",
    "    )\n",
    "    df = add_month_over_month_growth_features(df, monthly_growth_pct=store_config.get(\"monthly_growth_pct\", 1.0))\n",
    "    df = add_covid_store_features(\n",
    "        df,\n",
    "        covid_start=store_config.get(\"covid_start\", \"2020-03-01\"),\n",
    "        covid_drop_depth=store_config.get(\"covid_drop_depth\", 0.8),\n",
    "        covid_drop_sigma=store_config.get(\"covid_drop_sigma\", 100.0),\n",
    "        covid_recovery_rate=store_config.get(\"covid_recovery_rate\", 0.003),\n",
    "        covid_recovery_start=store_config.get(\"covid_recovery_start\", \"2023-06-01\"),\n",
    "    )\n",
    "    df = add_seasonality_features(\n",
    "        df,\n",
    "        winter_factor=store_config.get(\"winter_factor\", 0.95),\n",
    "        spring_factor=store_config.get(\"spring_factor\", 1.0),\n",
    "        summer_factor=store_config.get(\"summer_factor\", 1.1),\n",
    "        autumn_factor=store_config.get(\"autumn_factor\", 0.98),\n",
    "    )\n",
    "    df = add_total_impact_features(df)\n",
    "    df = explode_by_simulated_volume(df)\n",
    "    df = add_quantity_sold(df)\n",
    "    df = remove_helper_columns(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_df(df: DataFrame, name: str, path: str, fmt: str = \"csv\", single_file: bool = True, header: bool = True, mode: str = \"overwrite\") -> None:\n",
    "    path = f\"{path}/{name}\"\n",
    "    writer_df = df.coalesce(1) if single_file else df\n",
    "    writer = writer_df.write.mode(mode)\n",
    "\n",
    "    if fmt == \"csv\":\n",
    "        writer.option(\"header\", header).csv(path)\n",
    "    elif fmt == \"parquet\":\n",
    "        writer.parquet(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported format: {fmt}\")\n",
    "\n",
    "    print(f\"✅ Saved {name} as {fmt} to {path}\")\n",
    "\n",
    "\n",
    "def main(catalog: str):\n",
    "    volume_path = f\"/Volumes/{catalog}/bronze/raw\"\n",
    "\n",
    "    base_dates_df = date_generation(start_date=\"2010-01-01\", end_date=\"2025-12-31\")\n",
    "\n",
    "    store_configs: List[Dict] = [\n",
    "        {\n",
    "            \"store_key\": 1, \"store_start_date\": \"2010-01-01\", \"store_end_date\": \"2025-12-31\",\n",
    "            \"base_volume\": 26, \"covid_sales_impact_factor\": \"high\",\n",
    "            \"covid_impact_start_date\": \"2020-03-01\", \"covid_impact_end_date\": \"2022-12-31\",\n",
    "            \"noise_stddev\": 0.04, \"noise_seed\": 1, \"monthly_growth_pct\": 0.2,\n",
    "            \"mon_factor\": 0.95, \"tue_factor\": 1.05, \"wed_factor\": 1.10, \"thu_factor\": 1.10, \"fri_factor\": 1.15, \"sat_factor\": 1.10, \"sun_factor\": 1.0,\n",
    "            \"covid_start\": \"2020-03-15\", \"covid_drop_depth\": 0.85, \"covid_drop_sigma\": 110.0, \"covid_recovery_rate\": 0.0025, \"covid_recovery_start\": \"2022-01-01\",\n",
    "        },\n",
    "        {\n",
    "            \"store_key\": 2, \"store_start_date\": \"2012-06-01\", \"store_end_date\": \"2025-12-31\",\n",
    "            \"base_volume\": 18, \"covid_sales_impact_factor\": \"medium\",\n",
    "            \"covid_impact_start_date\": \"2020-03-01\", \"covid_impact_end_date\": \"2022-06-30\",\n",
    "            \"noise_stddev\": 0.05, \"noise_seed\": 2, \"monthly_growth_pct\": 0.15,\n",
    "            \"mon_factor\": 0.90, \"tue_factor\": 0.98, \"wed_factor\": 1.02, \"thu_factor\": 1.05, \"fri_factor\": 1.10, \"sat_factor\": 1.25, \"sun_factor\": 1.20,\n",
    "            \"covid_start\": \"2020-03-10\", \"covid_drop_depth\": 0.65, \"covid_drop_sigma\": 90.0, \"covid_recovery_rate\": 0.0040, \"covid_recovery_start\": \"2021-06-01\",\n",
    "        },\n",
    "        {\n",
    "            \"store_key\": 3, \"store_start_date\": \"2015-03-01\", \"store_end_date\": \"2025-12-31\",\n",
    "            \"base_volume\": 22, \"covid_sales_impact_factor\": \"high\",\n",
    "            \"covid_impact_start_date\": \"2020-03-15\", \"covid_impact_end_date\": \"2022-09-30\",\n",
    "            \"noise_stddev\": 0.06, \"noise_seed\": 3, \"monthly_growth_pct\": 0.01,\n",
    "            \"mon_factor\": 0.92, \"tue_factor\": 0.97, \"wed_factor\": 1.0, \"thu_factor\": 1.05, \"fri_factor\": 1.12, \"sat_factor\": 1.30, \"sun_factor\": 1.25,\n",
    "            \"covid_start\": \"2020-03-20\", \"covid_drop_depth\": 0.80, \"covid_drop_sigma\": 100.0, \"covid_recovery_rate\": 0.0030, \"covid_recovery_start\": \"2022-03-01\",\n",
    "        },\n",
    "        {\n",
    "            \"store_key\": 4, \"store_start_date\": \"2018-09-01\", \"store_end_date\": \"2025-12-31\",\n",
    "            \"base_volume\": 21, \"covid_sales_impact_factor\": \"very_high\",\n",
    "            \"covid_impact_start_date\": \"2020-03-01\", \"covid_impact_end_date\": \"2023-03-31\",\n",
    "            \"noise_stddev\": 0.05, \"noise_seed\": 4, \"monthly_growth_pct\": 0.4,\n",
    "            \"mon_factor\": 1.0, \"tue_factor\": 1.10, \"wed_factor\": 1.15, \"thu_factor\": 1.15, \"fri_factor\": 1.08, \"sat_factor\": 0.8, \"sun_factor\": 0.75,\n",
    "            \"covid_start\": \"2020-03-10\", \"covid_drop_depth\": 0.90, \"covid_drop_sigma\": 130.0, \"covid_recovery_rate\": 0.0020, \"covid_recovery_start\": \"2023-01-01\",\n",
    "        },\n",
    "        {\n",
    "            \"store_key\": 5, \"store_start_date\": \"2021-01-15\", \"store_end_date\": \"2025-12-31\",\n",
    "            \"base_volume\": 14, \"covid_sales_impact_factor\": \"low\",\n",
    "            \"covid_impact_start_date\": \"2021-01-15\", \"covid_impact_end_date\": \"2023-12-31\",\n",
    "            \"noise_stddev\": 0.07, \"noise_seed\": 5, \"monthly_growth_pct\": 0.5,\n",
    "            \"mon_factor\": 0.90, \"tue_factor\": 0.95, \"wed_factor\": 1.0, \"thu_factor\": 1.08, \"fri_factor\": 1.20, \"sat_factor\": 1.35, \"sun_factor\": 1.25,\n",
    "            \"covid_start\": \"2021-01-15\", \"covid_drop_depth\": 0.90, \"covid_drop_sigma\": 130.0, \"covid_recovery_rate\": 0.0045, \"covid_recovery_start\": \"2023-06-01\",\n",
    "        },\n",
    "        {\n",
    "            \"store_key\": 6, \"store_start_date\": \"2021-01-01\", \"store_end_date\": \"2025-12-31\",\n",
    "            \"base_volume\": 11, \"covid_sales_impact_factor\": \"low\",\n",
    "            \"covid_impact_start_date\": \"2020-05-01\", \"covid_impact_end_date\": \"2023-01-01\",\n",
    "            \"noise_stddev\": 0.05, \"noise_seed\": 6, \"monthly_growth_pct\": 1.0,\n",
    "            \"mon_factor\": 0.95, \"tue_factor\": 0.98, \"wed_factor\": 1.02, \"thu_factor\": 1.08, \"fri_factor\": 1.18, \"sat_factor\": 1.30, \"sun_factor\": 1.25,\n",
    "            \"covid_start\": \"2020-05-01\", \"covid_drop_depth\": -0.08, \"covid_drop_sigma\": 240.0, \"covid_recovery_rate\": 0.0002, \"covid_recovery_start\": \"2023-01-01\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    store_dfs = [build_store_dataframe(base_dates_df, cfg) for cfg in store_configs]\n",
    "    all_stores_df = reduce(lambda le, r: le.unionByName(r, allowMissingColumns=True), store_dfs) if len(store_dfs) > 1 else store_dfs[0]\n",
    "\n",
    "    all_stores_df = add_dim_product_key(all_stores_df)\n",
    "    all_stores_df = add_dim_customer_key(all_stores_df)\n",
    "\n",
    "    dim_dfs = {\n",
    "        \"dim_product\": create_dim_product(),\n",
    "        \"dim_customer\": create_dim_customer(),\n",
    "        \"dim_store\": create_dim_store(),\n",
    "        \"dim_date\": create_dim_date(),\n",
    "    }\n",
    "\n",
    "    for name, df in dim_dfs.items():\n",
    "        save_df(df, name, volume_path)\n",
    "\n",
    "    fact_table_path = f\"{volume_path}/fact_coffee_sales\"\n",
    "    all_stores_df.repartition(\"store_key\").write.mode(\"overwrite\").partitionBy(\"store_key\").parquet(fact_table_path)\n",
    "    print(f\"✅ Fact write complete: saved partitioned Parquet files to {fact_table_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c671141a-bf71-4187-9f79-5d571a2a79e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def init_catalog(catalog: str = \"sunny_bay_roastery\"):\n",
    "    spark.sql(f\"CREATE CATALOG IF NOT EXISTS `{catalog}`\")\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS `{catalog}`.bronze\")\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS `{catalog}`.silver\")\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS `{catalog}`.gold\")\n",
    "    spark.sql(f\"CREATE VOLUME IF NOT EXISTS `{catalog}`.bronze.raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08a41f31-b7ae-407a-b53a-32d836f5bf48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_stmts(catalog: str) -> List[str]:\n",
    "  with open(root / \"silver.sql\", \"r\") as f:\n",
    "      silver_query = f.read()\n",
    "\n",
    "  with open(root / \"gold.sql\", \"r\") as f:\n",
    "      gold_query = f.read()\n",
    "\n",
    "  query = silver_query.strip() + \"\\n\\n\" + gold_query.strip()\n",
    "  query = query.replace(\"${catalog}\", \"{catalog}\")\n",
    "  query = re.sub(r\"\\b(silver|gold)\\.\", r\"{catalog}.\\1.\", query)\n",
    "  query = query.replace(\"STREAMING \", \"\").replace(\"REFRESH\", \"REPLACE\").replace(\"MATERIALIZED VIEW\", \"TABLE\").replace(\"STREAM \", \"\")\n",
    "  query = query.format(catalog=catalog)\n",
    "\n",
    "  return [stmt.strip() for stmt in query.split(\";\") if stmt.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47645d21-bdeb-4638-8a19-489908bad238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "init_catalog(catalog)\n",
    "main(catalog)\n",
    "\n",
    "stmts = get_stmts(catalog)\n",
    "for i in stmts:\n",
    "    spark.sql(i)\n",
    "print(f\"✅ Initialized the bronze and silver tables in catalog `{catalog}`!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "init",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
